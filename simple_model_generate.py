# -*- coding: utf-8 -*-
"""Simple-Model-generate.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lMllFCA3qJgIoWuqn3JbBbXUGQFscnsf
"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Dense, Flatten
from tensorflow.keras.utils import to_categorical
# Load Dataset
(X_train, Y_train), (X_test, Y_test) = mnist.load_data()
# Normalize
X_train = X_train / 255.0
X_test = X_test / 255.0

# One-hot encoded
Y_train = to_categorical(Y_train, 10)
Y_test = to_categorical(Y_test, 10)

# Build model
model = Sequential()

model.add(Flatten(input_shape=(28,28)))
model.add(Dense(128, activation='relu'))
model.add(Dense(64, activation = 'relu'))
model.add(Dense(10, activation='softmax'))

# Compile
model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy'])
# Training
model.fit(X_train, Y_train, epochs=5, batch_size=32)

loss, accuracy = model.evaluate(X_test, Y_test)

print("Test Accuracy : ", accuracy)
prediction = model.predict(X_test[:5])
print("Predidiction : ", np.argmax(prediction, axis=1))

from IPython.core import history
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Dense, Flatten
from tensorflow.keras.utils import to_categorical

# Dataset Load
(x_train , y_train), (x_test, y_test) = mnist.load_data()

# Data Processing
# Normalize data
x_train = x_train / 255.0
x_test = x_test / 255.0

# one-hot method
y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)

# Model build
model = Sequential()

model.add(Flatten(input_shape=(28,28)))
model.add(Dense(164, activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(10, activation='softmax'))

# Compile
model.compile(optimizer ='adam', loss = 'categorical_crossentropy', metrics=['accuracy'])

# Test
history = model.fit(x_train , y_train , epochs = 5)

loss , accuracy = model.evaluate(x_test, y_test)
pred_y = model.predict(x_test)
print("total Loss: ", loss)
print("Total accuracy: ", accuracy)

print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)
# If you want to visualize training history (loss/accuracy over epochs):
# plt.figure(figsize=(12, 5))
# plt.plot(history.history['loss'], label='Training Loss')
# plt.plot(history.history['accuracy'], label='Training Accuracy')
# plt.title('Model Loss and Accuracy Over Epochs')
# plt.xlabel('Epoch')
# plt.ylabel('Value')
# plt.legend()
# plt.show()

|